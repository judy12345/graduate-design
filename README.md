# Sparse-Adversarial-Attack
Implementation for **Bechlor graduate design**

In this work, we propose an adversarial sample attack method namely APA: an untargeted attack method based on attention mechanism. The detection and classification performance of the target detector is attacked by adding "cross-
shaped" patches to the key parts of the image (i.e., the feature area of the input image that the target detector pays attention to and the horizontal and vertical areas where the center point of the detection frame is located).

To reproduce the attack performance:
   Run ```train_GraD.py``` to generate the attacked graph
